import torch
import whisper
import os
import time
import openai
import json

# --- 1. åˆå§‹åŒ–æ¨¡å‹å’Œå®¢æˆ·ç«¯ ---
# (è¿™éƒ¨åˆ†ä»£ç ä¿æŒä¸å˜ï¼Œå‡è®¾æ‚¨å·²ç»å¡«å…¥äº†æœ‰æ•ˆçš„API Keyå’Œé…ç½®)
device = "cuda:0" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

print("Loading Speech-to-Text (Whisper) model...")
asr_model = whisper.load_model("base", device=device)
print("\n--- ASR model loaded successfully! ---\n")

# --- åˆå§‹åŒ– LLM å®¢æˆ·ç«¯ (ä»¥DeepSeekä¸ºä¾‹ï¼Œä¹Ÿå¯æ¢æˆOpenAI) ---
try:
    # æ›¿æ¢æˆä½ çš„API Key
    api_key = "sk-ae92957e3964439e9b2fac3660d8ddff"
    if not api_key:
        raise ValueError("API_KEY environment variable not found.")

    client = openai.OpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com/v1" # å¦‚æœç”¨ChatGPTï¼Œè¯·æ³¨é‡Šæˆ–åˆ é™¤æ­¤è¡Œ
    )
    client.models.list() # æµ‹è¯•è¿æ¥
    print("--- LLM client initialized successfully! ---\n")
    
except Exception as e:
    print(f"--- [ERROR] Failed to initialize LLM client: {e} ---")
    client = None


# --- 2. å®šä¹‰åˆ†æå‡½æ•° ---

PROMPT = "è¿™æ˜¯ä¸€æ®µå¯èƒ½åŒ…å«é‡‘èã€è½¬è´¦ã€æ±‡æ¬¾ã€éªŒè¯ç ã€é“¶è¡Œã€è´¦æˆ·ç­‰è¯è¯­çš„å¯¹è¯ã€‚"

def analyze_scam_with_llm(text_to_analyze: str, model_name="deepseek-chat"):
    """
    ä½¿ç”¨LLMè¿›è¡Œæ·±åº¦åˆ†æï¼Œå¼•å…¥â€œåˆæ³•æ€§æ£€æŸ¥ç‚¹â€ä»¥é™ä½è¯¯æŠ¥ç‡ã€‚
    """
    if not client:
        return {"error": "LLM client not available."}

    # ã€æ ¸å¿ƒå‡çº§ã€‘å¼•å…¥â€œåˆæ³•æ€§æ£€æŸ¥ç‚¹â€çš„å…¨æ–°System Prompt
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªæå…¶ä¸¥è°¨ã€æ³¨é‡é€»è¾‘çš„â€œå¯¹è¯å®šæ€§åˆ†æå¸ˆâ€ï¼Œä¸“æ”»åè¯ˆéª—é¢†åŸŸã€‚è¯¯æŠ¥ä¸€ä¸ªæ­£å¸¸é€šè¯æ˜¯å¯¹ç”¨æˆ·çš„ä¸¥é‡éªšæ‰°ï¼Œå¿…é¡»æåŠ›é¿å…ã€‚

    ä½ çš„ä»»åŠ¡æ˜¯åˆ†æä¸€æ®µå•æ–¹é¢çš„è®²è¯æ–‡æœ¬ã€‚åœ¨åˆ¤æ–­å…¶æ˜¯å¦ä¸ºè¯ˆéª—å‰ï¼Œä½ å¿…é¡»å…ˆè¿›è¡Œã€åˆæ³•æ€§æ£€æŸ¥ã€‘ã€‚

    **ã€åˆæ³•æ€§æ£€æŸ¥ç‚¹ã€‘**
    ä¸€æ®µæ­£å¸¸çš„å®˜æ–¹æˆ–å®¢æœé€šè¯ï¼Œé€šå¸¸ä¼šåŒ…å«ä»¥ä¸‹ä¸€ä¸ªæˆ–å¤šä¸ªç‰¹å¾ã€‚è¯·æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ç¬¦åˆï¼š
    1.  **å¼•å¯¼è‡³å®˜æ–¹æ¸ é“ (Official Channel Guidance)**ï¼šæ˜¯å¦æ˜ç¡®å¼•å¯¼ç”¨æˆ·é€šè¿‡å®˜æ–¹Appã€å®˜ç½‘ã€å°ç¨‹åºæˆ–çº¿ä¸‹å®ä½“ç½‘ç‚¹è¿›è¡Œæ“ä½œï¼Ÿï¼ˆä¾‹å¦‚ï¼šâ€œè¯¦æƒ…è¯·ç™»å½•æ‰‹æœºé“¶è¡ŒAppæŸ¥çœ‹â€ã€â€œæ‚¨å¯åœ¨APPå†…æ“ä½œâ€ã€â€œè¯·å‰å¾€æ´¾å‡ºæ‰€åŠç†â€ï¼‰
    2.  **å£°æ˜æ— å®³æ“ä½œ (Harmless Action Statement)**ï¼šæ˜¯å¦æ˜ç¡®å£°æ˜æœ¬æ¬¡é€šè¯ä¸æ¶‰åŠæ”¶è´¹ã€ä¸è¦æ±‚è½¬è´¦ã€æˆ–é€€æ¬¾ä¼šåŸè·¯è¿”å›ï¼Ÿï¼ˆä¾‹å¦‚ï¼šâ€œæœ¬æ¬¡ä¸æ¶‰åŠä»»ä½•è´¹ç”¨æ”¶å–â€ã€â€œç¥¨æ¬¾å°†åŸè·¯é€€å›â€ã€â€œæˆ‘ä»¬å°†è‡ªåŠ¨èµ”ä»˜æ‚¨ä¸‰å…ƒè¿è´¹çº¢åŒ…â€ï¼‰
    3.  **ä¿¡æ¯åŒæ­¥è€Œéç´¢å– (Information Sync, Not Phishing)**ï¼šé€šè¯å†…å®¹ä¸»è¦æ˜¯åŒæ­¥ä¿¡æ¯ã€æé†’æˆ–é€šçŸ¥ï¼Œè€Œæ²¡æœ‰ä¸»åŠ¨ç´¢å–ç”¨æˆ·çš„å¯†ç ã€éªŒè¯ç ã€é“¶è¡Œå¡è¯¦æƒ…ç­‰æ•æ„Ÿä¿¡æ¯ï¼Ÿ

    åªæœ‰åœ¨ä¸€æ®µè¯**å®Œå…¨ä¸ç¬¦åˆ**ä¸Šè¿°ä»»ä½•åˆæ³•æ€§ç‰¹å¾ï¼Œ**å¹¶ä¸”**åŒæ—¶è¡¨ç°å‡ºæ˜ç¡®çš„è¯ˆéª—æ„å›¾ï¼ˆå¦‚å¼•å¯¼æ·»åŠ ç§äººå¾®ä¿¡/QQã€è¦æ±‚è½¬è´¦åˆ°å®‰å…¨è´¦æˆ·ã€å¼•å¯¼å±å¹•å…±äº«ç­‰ï¼‰æ—¶ï¼Œæ‰èƒ½å°†å…¶åˆ¤å®šä¸ºè¯ˆéª—ã€‚

    ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„JSONæ ¼å¼å¯¹è±¡ï¼Œä¸è¦åŒ…å«ä»»ä½•ä¸JSONæ— å…³çš„æ–‡å­—ã€‚
    JSONå¯¹è±¡çš„ç»“æ„å¿…é¡»å¦‚ä¸‹ï¼š
    {
      "legitimacy_checks": {
        "official_channel_guidance": boolean,
        "harmless_action_statement": boolean,
        "is_information_sync": boolean
      },
      "final_assessment": {
        "is_scam": boolean,
        "risk_level": "string",
        "scam_type": "string",
        "reasoning": "string"
      }
    }

    å­—æ®µè¯´æ˜ï¼š
    - **legitimacy_checks**: åˆæ³•æ€§æ£€æŸ¥çš„ç»“æœã€‚
      - `official_channel_guidance`: å¦‚æœæ–‡æœ¬å¼•å¯¼ç”¨æˆ·èµ°å®˜æ–¹æ¸ é“ï¼Œåˆ™ä¸ºtrueã€‚
      - `harmless_action_statement`: å¦‚æœæ–‡æœ¬æ˜ç¡®è¡¨ç¤ºæ“ä½œæ— å®³ï¼ˆä¸æ”¶è´¹/åŸè·¯é€€æ¬¾ï¼‰ï¼Œåˆ™ä¸ºtrueã€‚
      - `is_information_sync`: å¦‚æœæ–‡æœ¬ä¸»è¦æ˜¯ä¿¡æ¯åŒæ­¥ï¼Œåˆ™ä¸ºtrueã€‚
    - **final_assessment**: æœ€ç»ˆè¯„ä¼°ã€‚
      - `is_scam`: **åªæœ‰åœ¨ä¸Šè¿°ä¸‰é¡¹åˆæ³•æ€§æ£€æŸ¥å¤§éƒ¨åˆ†ä¸ºfalseï¼Œä¸”å­˜åœ¨æ˜ç¡®è¯ˆéª—è¡Œä¸ºæ—¶ï¼Œæ‰ä¸ºtrueã€‚**
      - `risk_level`: é£é™©ç­‰çº§ï¼Œåªèƒ½æ˜¯["é«˜é£é™©", "ä¸­é£é™©", "ä½é£é™©", "æ— é£é™©"]ã€‚
      - `scam_type`: è¯ˆéª—ç±»å‹ï¼Œä¾‹å¦‚ï¼š"å†’å……å®¢æœé€€æ¬¾"ã€"åˆ·å•è¿”åˆ©"ã€"å†’å……å…¬æ£€æ³•"ã€"ç´¢è¦éªŒè¯ç "ã€"æ€çŒªç›˜"ã€"æœªçŸ¥" æˆ– "ä¸é€‚ç”¨"ã€‚
      - `reasoning`: è¯¦ç»†è¯´æ˜ä½ åšå‡ºåˆ¤æ–­çš„ç†ç”±ï¼Œå¿…é¡»ç»“åˆã€åˆæ³•æ€§æ£€æŸ¥ç‚¹ã€‘çš„ç»“æœè¿›è¡Œè§£é‡Šã€‚
    """
    
    # ã€æ ¸å¿ƒå‡çº§ã€‘æ–°çš„User Prompt
    user_prompt = f"è¯·ä¸¥æ ¼éµå¾ªä½ è¢«è®¾å®šçš„â€œå¯¹è¯å®šæ€§åˆ†æå¸ˆâ€è§’è‰²å’Œåˆ†ææ¡†æ¶ï¼Œå¯¹ä»¥ä¸‹è®²è¯æ–‡æœ¬è¿›è¡Œã€åˆæ³•æ€§æ£€æŸ¥ã€‘å’Œæœ€ç»ˆè¯„ä¼°ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§è¦æ±‚çš„JSONæ ¼å¼è¿”å›ç»“æœã€‚\n\n--- è®²è¯æ–‡æœ¬ ---\n\"{text_to_analyze}\"\n--- ç»“æŸ ---"
    
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
            response_format={"type": "json_object"}, 
            temperature=0.0 # å¯¹äºåˆ†ç±»å’Œç»“æ„åŒ–è¾“å‡ºï¼Œä½¿ç”¨0æ¸©åº¦ä»¥è·å¾—æœ€ç¨³å®šã€å¯å¤ç°çš„ç»“æœ
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        print(f"   [LLM ERROR] LLM API call failed: {e}")
        return {"error": str(e)}

def analyze_audio_for_scam(audio_path):
    print(f"-> Processing: {os.path.basename(audio_path)}...")
    result = {"filename": os.path.basename(audio_path), "transcription": "", "llm_analysis": None}
    try:
        transcription_result = asr_model.transcribe(
            audio_path, language="zh", fp16=torch.cuda.is_available(), initial_prompt=PROMPT
        )
        transcribed_text = transcription_result['text'].strip()
        result["transcription"] = transcribed_text
        if transcribed_text:
            print(f"   Transcript: \"{transcribed_text}\"")
            if client:
                print("   -> Sending to LLM for advanced analysis...")
                llm_analysis_result = analyze_scam_with_llm(transcribed_text)
                result["llm_analysis"] = llm_analysis_result
                if llm_analysis_result and "error" not in llm_analysis_result:
                    assessment = llm_analysis_result.get("final_assessment", {})
                    risk = assessment.get('risk_level', 'æœªçŸ¥')
                    scam_type = assessment.get('scam_type', 'æœªçŸ¥')
                    print(f"   [LLM Result] Risk Level: {risk}, Scam Type: {scam_type}")
                else:
                    print("   [LLM Result] Analysis failed or returned an error.")
            else:
                 print("   [LLM SKIPPED] LLM client not available.")
        else:
             print("   - Transcription is empty.")
    except Exception as e:
        print(f"   [FATAL ERROR] æ— æ³•å¤„ç†æ–‡ä»¶ {os.path.basename(audio_path)}. Reason: {e}")
        result["transcription"] = f"Error: {e}"
    return result

# --- ã€æ ¸å¿ƒå‡çº§ã€‘å…¨æ–°çš„æ€»ç»“æŠ¥å‘Šå‡½æ•°ï¼Œèƒ½å±•ç¤ºåˆæ³•æ€§æ£€æŸ¥ç»“æœ ---
def print_scam_summary_report(all_results):
    """
    ç”Ÿæˆä¸€ä»½è¯¦ç»†çš„æ€»ç»“æŠ¥å‘Šï¼ŒåŒ…å«åˆæ³•æ€§æ£€æŸ¥ç»“æœï¼Œä»¥åˆ†æè¯¯æŠ¥åŸå› ã€‚
    """
    risk_categories = {"é«˜é£é™©": [], "ä¸­é£é™©": [], "ä½é£é™©": [], "æ— é£é™©": [], "åˆ†æå¤±è´¥": []}
    
    for res in all_results:
        analysis = res.get("llm_analysis")
        if res["transcription"].startswith("Error:") or not analysis or "error" in analysis:
            risk_categories["åˆ†æå¤±è´¥"].append(res)
        else:
            risk_level = analysis.get("final_assessment", {}).get("risk_level", "åˆ†æå¤±è´¥")
            risk_categories.get(risk_level, risk_categories["åˆ†æå¤±è´¥"]).append(res)

    print("\n" + "="*80)
    print("           ğŸš¨  LLM åè¯ˆéª—æ™ºèƒ½åˆ†ææ€»ç»“æŠ¥å‘Š (V2 - é€»è¾‘å¢å¼ºç‰ˆ)  ğŸš¨")
    print("="*80)
    print(f"æ€»å…±åˆ†æäº† {len(all_results)} ä¸ªéŸ³é¢‘æ–‡ä»¶ã€‚\n")

    for risk, files in risk_categories.items():
        if not files:
            continue
        
        icon = {"é«˜é£é™©": "ğŸ”¥ğŸ”¥ğŸ”¥", "ä¸­é£é™©": "âš ï¸", "ä½é£é™©": "â¡ï¸", "æ— é£é™©": "âœ…", "åˆ†æå¤±è´¥": "âŒ"}.get(risk)
        print(f"{icon}ã€{risk}ã€‘éŸ³é¢‘ ({len(files)}ä¸ª)")
        
        for res in files:
            print(f"\n  ğŸ“„ æ–‡ä»¶å: {res['filename']}")
            print(f"     è½¬å½•å†…å®¹: \"{res['transcription']}\"")
            
            analysis = res.get("llm_analysis")
            if analysis and "final_assessment" in analysis:
                assessment = analysis["final_assessment"]
                checks = analysis.get("legitimacy_checks", {})
                
                print(f"     åˆæ³•æ€§æ£€æŸ¥:")
                print(f"       - å¼•å¯¼è‡³å®˜æ–¹æ¸ é“: {checks.get('official_channel_guidance', 'N/A')}")
                print(f"       - å£°æ˜æ— å®³æ“ä½œ:   {checks.get('harmless_action_statement', 'N/A')}")
                print(f"       - ä¿¡æ¯åŒæ­¥ä¸ºä¸»:   {checks.get('is_information_sync', 'N/A')}")
                
                print(f"     æœ€ç»ˆè¯„ä¼°:")
                print(f"       - è¯ˆéª—ç±»å‹: {assessment.get('scam_type', 'N/A')}")
                print(f"       - åˆ¤æ–­ç†ç”±: {assessment.get('reasoning', 'N/A')}")
            else:
                print("     [åˆ†æå¤±è´¥æˆ–æ ¼å¼é”™è¯¯]")
        print("-" * 80)
            
    print("\næŠ¥å‘Šç»“æŸã€‚")

# --- ã€æ ¸å¿ƒå‡çº§ã€‘æ€§èƒ½è¯„ä¼°å‡½æ•°ï¼Œé€‚é…æ–°JSONç»“æ„ ---
def calculate_performance_metrics(all_results, scam_audio_count):
    true_positive, false_positive, true_negative, false_negative = 0, 0, 0, 0
    total_audios = len(all_results)
    
    for i, res in enumerate(all_results):
        is_true_scam = (i < scam_audio_count)
        
        is_predicted_scam = False
        llm_analysis = res.get("llm_analysis")
        if llm_analysis and isinstance(llm_analysis, dict):
            # é€‚é…æ–°çš„JSONç»“æ„
            assessment = llm_analysis.get("final_assessment", {})
            if isinstance(assessment, dict):
                is_predicted_scam = assessment.get("is_scam", False) is True
        
        if is_true_scam and is_predicted_scam: true_positive += 1
        elif not is_true_scam and is_predicted_scam: false_positive += 1
        elif not is_true_scam and not is_predicted_scam: true_negative += 1
        elif is_true_scam and not is_predicted_scam: false_negative += 1
    
    print("\n" + "="*80)
    print("                 ğŸ“ˆ  æ¨¡å‹æ€§èƒ½è¯„ä¼°ç»Ÿè®¡ (V2 - é€»è¾‘å¢å¼ºç‰ˆ)  ğŸ“ˆ")
    print("="*80)
    
    print(f"æµ‹è¯•é›†ä¿¡æ¯:\n  - æ€»æ ·æœ¬æ•°: {total_audios}\n  - çœŸå®è¯ˆéª—æ ·æœ¬æ•° (Positive): {scam_audio_count}\n  - çœŸå®æ­£å¸¸æ ·æœ¬æ•° (Negative): {total_audios - scam_audio_count}")
    print("-" * 40)
    print(f"æ··æ·†çŸ©é˜µ (Confusion Matrix):\n  - çœŸæ­£è¯ˆéª— (TP): {true_positive}\n  - è¯¯æŠ¥è¯ˆéª— (FP): {false_positive}\n  - çœŸæ­£æ­£å¸¸ (TN): {true_negative}\n  - æ¼æŠ¥è¯ˆéª— (FN): {false_negative}")
    print("-" * 40)
    
    accuracy = (true_positive + true_negative) / total_audios if total_audios > 0 else 0
    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0
    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    
    print(f"æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡:\n  - å‡†ç¡®ç‡ (Accuracy): {accuracy:.2%}\n  - ç²¾ç¡®ç‡ (Precision): {precision:.2%}\n  - å¬å›ç‡ (Recall): {recall:.2%}\n  - F1åˆ†æ•° (F1-Score): {f1_score:.2f}")
    print("\n" + "="*80)

# --- 3. æ‰¹é‡è¿è¡Œåˆ†æ ---
if __name__ == "__main__":
    AUDIO_DIRECTORY = "call_cases2" 
    REAL_SCAM_AUDIO_COUNT = 20 # å‡è®¾å‰20ä¸ªæ˜¯è¯ˆéª—æ ·æœ¬
    
    supported_formats = ('.wav', '.mp3', '.m4a', '.flac', '.ogg')

    if not os.path.isdir(AUDIO_DIRECTORY):
        print(f"\né”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶å¤¹ '{AUDIO_DIRECTORY}'ã€‚")
    elif client is None:
        print("\nç¨‹åºæ— æ³•ç»§ç»­ï¼Œå› ä¸º LLM å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ã€‚")
    else:
        audio_files = sorted([f for f in os.listdir(AUDIO_DIRECTORY) if f.lower().endswith(supported_formats)])
        
        if not audio_files:
            print(f"åœ¨æ–‡ä»¶å¤¹ '{AUDIO_DIRECTORY}' ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„éŸ³é¢‘æ–‡ä»¶ã€‚")
        else:
            print(f"åœ¨ '{AUDIO_DIRECTORY}' ä¸­æ‰¾åˆ° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œå‡†å¤‡è¿›è¡Œåè¯ˆéª—åˆ†æ...\n")
            
            all_analysis_results = []
            start_time = time.time()
            
            for filename in audio_files:
                file_path = os.path.join(AUDIO_DIRECTORY, filename)
                analysis_result = analyze_audio_for_scam(file_path)
                all_analysis_results.append(analysis_result)
            
            end_time = time.time()
            
            print_scam_summary_report(all_analysis_results)
            calculate_performance_metrics(all_analysis_results, REAL_SCAM_AUDIO_COUNT)
            
            print(f"æ€»è€—æ—¶: {end_time - start_time:.2f} ç§’")